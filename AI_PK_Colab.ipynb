{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "AI_PK_Colab.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ” AI PK System - Google Colab Version\n",
        "\n",
        "AI A â†” AI B cross-verification with OpenAI arbitration\n",
        "\n",
        "## Setup Instructions:\n",
        "1. Add your API keys in **Colab Secrets** (ğŸ”‘ icon in left sidebar)\n",
        "2. Add your ngrok token as `NGROK_TOKEN`\n",
        "3. Run all cells in order"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install dependencies\n",
        "!pip install -q flask pyngrok google-generativeai openai"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load API keys from Colab Secrets\n",
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Configure ngrok\n",
        "ngrok.set_auth_token(userdata.get('NGROK_TOKEN'))\n",
        "\n",
        "# Load API keys\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "GROK_API_KEY = userdata.get('GROK_API_KEY')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "DOUBAO_API_KEY = userdata.get('DOUBAO_API_KEY')\n",
        "DOUBAO_ENDPOINT_ID = userdata.get('DOUBAO_ENDPOINT_ID')\n",
        "QWEN_API_KEY = userdata.get('QWEN_API_KEY')\n",
        "\n",
        "print('âœ… API keys loaded from Colab Secrets')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Flask App Setup\n",
        "import json\n",
        "from flask import Flask, request, jsonify, Response\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Model configuration\n",
        "MODEL_GEMINI = \"gemini-2.5-flash\"\n",
        "MODEL_GROK = \"grok-4-1-fast-reasoning\"\n",
        "MODEL_OPENAI = \"gpt-4o\"\n",
        "MODEL_DOUBAO = \"doubao-pro-32k\"\n",
        "MODEL_QWEN = \"qwen-max\"\n",
        "MAX_REVISION_ROUNDS = 3\n",
        "\n",
        "AVAILABLE_MODELS = {\n",
        "    'gemini': {'name': 'Gemini', 'display_name': 'Gemini (Google)', 'icon': 'G', 'color': '#4285f4'},\n",
        "    'grok': {'name': 'Grok', 'display_name': 'Grok (xAI)', 'icon': 'X', 'color': '#ff6b35'},\n",
        "    'doubao': {'name': 'Doubao', 'display_name': 'è±†åŒ… (ByteDance)', 'icon': 'è±†', 'color': '#00d4aa'},\n",
        "    'qwen': {'name': 'Qwen', 'display_name': 'åƒé—® (Alibaba)', 'icon': 'åƒ', 'color': '#ff5722'}\n",
        "}\n",
        "\n",
        "# Configure clients\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel(MODEL_GEMINI)\n",
        "grok_client = OpenAI(api_key=GROK_API_KEY, base_url=\"https://api.x.ai/v1\")\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "doubao_client = OpenAI(api_key=DOUBAO_API_KEY, base_url=\"https://ark.cn-beijing.volces.com/api/v3\")\n",
        "qwen_client = OpenAI(api_key=QWEN_API_KEY, base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\")\n",
        "\n",
        "print('âœ… AI clients configured')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: AI Model Functions\n",
        "def ask_gemini(prompt):\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return True, response.text\n",
        "    except Exception as e:\n",
        "        return False, f\"Gemini error: {e}\"\n",
        "\n",
        "def ask_grok(user_message):\n",
        "    try:\n",
        "        response = grok_client.chat.completions.create(\n",
        "            model=MODEL_GROK, messages=[{\"role\": \"user\", \"content\": user_message}])\n",
        "        return True, response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return False, f\"Grok error: {e}\"\n",
        "\n",
        "def ask_doubao(user_message):\n",
        "    try:\n",
        "        response = doubao_client.chat.completions.create(\n",
        "            model=DOUBAO_ENDPOINT_ID, messages=[{\"role\": \"user\", \"content\": user_message}])\n",
        "        return True, response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return False, f\"Doubao error: {e}\"\n",
        "\n",
        "def ask_qwen(user_message):\n",
        "    try:\n",
        "        response = qwen_client.chat.completions.create(\n",
        "            model=MODEL_QWEN, messages=[{\"role\": \"user\", \"content\": user_message}])\n",
        "        return True, response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return False, f\"Qwen error: {e}\"\n",
        "\n",
        "def ask_openai(prompt):\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=MODEL_OPENAI,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„äº‹å®æ ¸æŸ¥ä»²è£è€…ã€‚ä½ çš„åˆ¤æ–­å¿…é¡»å‡†ç¡®ï¼Œå°¤å…¶è¦è¯†åˆ«AIç¼–é€ è™šå‡ä¿¡æ¯ï¼ˆå¹»è§‰ï¼‰çš„æƒ…å†µã€‚\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.1)\n",
        "        return True, response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return False, f\"OpenAI error: {e}\"\n",
        "\n",
        "def ask_model(model_id, prompt):\n",
        "    if model_id == 'gemini': return ask_gemini(prompt)\n",
        "    elif model_id == 'grok': return ask_grok(prompt)\n",
        "    elif model_id == 'doubao': return ask_doubao(prompt)\n",
        "    elif model_id == 'qwen': return ask_qwen(prompt)\n",
        "    else: return False, f\"Unknown model: {model_id}\"\n",
        "\n",
        "def get_model_name(model_id):\n",
        "    return AVAILABLE_MODELS.get(model_id, {}).get('name', model_id)\n",
        "\n",
        "print('âœ… AI functions defined')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Prompt Templates\n",
        "def create_verification_prompt(question, answer):\n",
        "    return f\"\"\"\n",
        "    æˆ‘æœ‰ä¸€ä¸ªé—®é¢˜: \"{question}\"\n",
        "    å¦ä¸€ä¸ª AI æ¨¡å‹ç»™å‡ºäº†ä»¥ä¸‹å›ç­”:\n",
        "    ---\n",
        "    {answer}\n",
        "    ---\n",
        "    è¯·ä½œä¸ºä¸€åä¸¥å‰ã€å®¢è§‚çš„äº‹å®æ ¸æŸ¥å‘˜ï¼Œè¯„ä»·ä¸Šè¿°å›ç­”ã€‚\n",
        "    ä½ éœ€è¦ï¼š\n",
        "    1. æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„äº‹å®æ€§é”™è¯¯ã€‚\n",
        "    2. æŒ‡å‡ºé€»è¾‘æ¼æ´ã€‚\n",
        "    3. å¦‚æœå›ç­”éå¸¸å®Œç¾ï¼Œè¯·æ˜ç¡®è¯´\"å®Œç¾\"æˆ–\"æ— éœ€ä¿®æ”¹\"ã€‚\n",
        "    é‡è¦è¯´æ˜ï¼šä¸åŒAIæœ‰ä¸åŒçš„çŸ¥è¯†æˆªæ­¢æ—¥æœŸã€‚å¦‚æœä½ æ— æ³•æ ¸å®æŸäº›è¿‘æœŸäº‹ä»¶ï¼Œè¿™å¹¶ä¸æ„å‘³ç€å¯¹æ–¹ç¼–é€ äº†ä¿¡æ¯ã€‚\n",
        "    è¯·ç›´æ¥ç»™å‡ºä½ çš„è¯„å®¡æ„è§ã€‚\n",
        "    \"\"\"\n",
        "\n",
        "def create_arbiter_prompt(question, answer, review):\n",
        "    return f\"\"\"ä½ æ˜¯ä¸€ä¸ªå…¬æ­£ä¸¥æ ¼çš„ä»²è£è€…ã€‚åˆ†æä»¥ä¸‹è¯„å®¡æ„è§ï¼Œåˆ¤æ–­å›ç­”æ˜¯å¦éœ€è¦ä¿®æ­£ã€‚\n",
        "åŸå§‹é—®é¢˜: \"{question}\"\n",
        "AI çš„å›ç­”:\n",
        "---\n",
        "{answer}\n",
        "---\n",
        "å¦ä¸€ä¸ª AI çš„è¯„å®¡æ„è§:\n",
        "---\n",
        "{review}\n",
        "---\n",
        "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š\n",
        "{{\"needs_revision\": trueæˆ–false, \"reason\": \"ç®€çŸ­è¯´æ˜ç†ç”±\", \"corrections\": \"å¦‚éœ€ä¿®è®¢ï¼Œåˆ—å‡ºå…·ä½“ä¿®æ­£è¦ç‚¹ï¼›å¦åˆ™ä¸ºç©º\"}}\n",
        "\"\"\"\n",
        "\n",
        "def create_revision_prompt(question, original_answer, corrections):\n",
        "    return f\"\"\"\n",
        "é’ˆå¯¹é—®é¢˜: \"{question}\"\n",
        "ä½ ä¹‹å‰çš„å›ç­”å­˜åœ¨é—®é¢˜:\n",
        "---\n",
        "{original_answer}\n",
        "---\n",
        "è¯„å®¡å‘ç°ä»¥ä¸‹é—®é¢˜éœ€è¦ä¿®æ­£:\n",
        "---\n",
        "{corrections}\n",
        "---\n",
        "è¯·ç»™å‡ºä¿®æ­£åçš„å›ç­”ã€‚\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "def parse_arbiter_response(response):\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result.get(\"needs_revision\", False), result.get(\"corrections\", \"\") or result.get(\"reason\", \"\")\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "    json_match = re.search(r'\\{[^{}]*\"needs_revision\"[^{}]*\\}', response, re.DOTALL)\n",
        "    if json_match:\n",
        "        try:\n",
        "            result = json.loads(json_match.group())\n",
        "            return result.get(\"needs_revision\", False), result.get(\"corrections\", \"\") or result.get(\"reason\", \"\")\n",
        "        except: pass\n",
        "    if \"å®Œç¾\" in response or \"æ— éœ€ä¿®æ”¹\" in response:\n",
        "        return False, \"\"\n",
        "    return False, \"\"\n",
        "\n",
        "print('âœ… Prompt templates defined')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: HTML Template (stored as string)\n",
        "HTML_TEMPLATE = open('index_template.html').read() if False else '''<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>AI PK System</title>\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap\" rel=\"stylesheet\">\n",
        "    <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
        "    <style>\n",
        "        :root { --bg-primary: #0f0f1a; --bg-secondary: #1a1a2e; --bg-card: #16162a; --text-primary: #ffffff; --text-secondary: #a0a0c0; --gemini-color: #4285f4; --grok-color: #ff6b35; --openai-color: #10a37f; --border-color: rgba(255,255,255,0.08); }\n",
        "        * { margin: 0; padding: 0; box-sizing: border-box; }\n",
        "        body { font-family: 'Inter', sans-serif; background: var(--bg-primary); color: var(--text-primary); min-height: 100vh; line-height: 1.6; }\n",
        "        .container { max-width: 1400px; margin: 0 auto; padding: 40px 20px; }\n",
        "        .header { text-align: center; margin-bottom: 40px; }\n",
        "        .header h1 { font-size: 2.5rem; font-weight: 700; background: linear-gradient(135deg, #4285f4, #ff6b35, #10a37f); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin-bottom: 10px; }\n",
        "        .header p { color: var(--text-secondary); font-size: 1.1rem; }\n",
        "        .input-section { background: var(--bg-card); border-radius: 20px; padding: 30px; margin-bottom: 40px; border: 1px solid var(--border-color); }\n",
        "        .model-selectors { display: flex; gap: 20px; margin-bottom: 20px; }\n",
        "        .model-selector { flex: 1; display: flex; flex-direction: column; gap: 8px; }\n",
        "        .model-selector label { font-size: 0.85rem; color: var(--text-secondary); }\n",
        "        .model-selector select { background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 10px; padding: 12px 16px; color: var(--text-primary); font-size: 0.95rem; cursor: pointer; }\n",
        "        .input-wrapper { display: flex; gap: 15px; }\n",
        "        .question-input { flex: 1; background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; padding: 18px 24px; color: var(--text-primary); font-size: 1rem; outline: none; }\n",
        "        .submit-btn { background: linear-gradient(135deg, #4285f4, #34a853); border: none; border-radius: 12px; padding: 18px 40px; color: white; font-size: 1rem; font-weight: 600; cursor: pointer; }\n",
        "        .submit-btn:disabled { opacity: 0.6; cursor: not-allowed; }\n",
        "        .status-bar { background: var(--bg-secondary); border-radius: 12px; padding: 15px 25px; margin-bottom: 30px; display: flex; align-items: center; gap: 15px; opacity: 0; }\n",
        "        .status-bar.active { opacity: 1; }\n",
        "        .spinner { width: 20px; height: 20px; border: 2px solid var(--border-color); border-top-color: var(--gemini-color); border-radius: 50%; animation: spin 1s linear infinite; }\n",
        "        @keyframes spin { to { transform: rotate(360deg); } }\n",
        "        .response-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-bottom: 30px; }\n",
        "        .response-card { background: var(--bg-card); border-radius: 20px; overflow: hidden; border: 1px solid var(--border-color); }\n",
        "        .response-header { padding: 20px 25px; display: flex; align-items: center; gap: 12px; }\n",
        "        .ai-icon { width: 40px; height: 40px; background: rgba(255,255,255,0.2); border-radius: 10px; display: flex; align-items: center; justify-content: center; font-weight: 700; font-size: 1.2rem; }\n",
        "        .response-title { font-size: 1.3rem; font-weight: 600; }\n",
        "        .response-content { padding: 25px; min-height: 200px; max-height: 500px; overflow-y: auto; }\n",
        "        .arbiter-section { background: var(--bg-card); border-radius: 20px; overflow: hidden; border: 1px solid var(--border-color); }\n",
        "        .arbiter-header { padding: 20px 25px; background: linear-gradient(135deg, #10a37f, #1a7f64); display: flex; align-items: center; gap: 12px; }\n",
        "        .arbiter-content { padding: 25px; }\n",
        "        .arbiter-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }\n",
        "        .arbiter-item { background: var(--bg-secondary); border-radius: 12px; padding: 20px; }\n",
        "        .consensus-banner { text-align: center; padding: 30px; margin-top: 20px; }\n",
        "        .consensus-badge { display: inline-flex; align-items: center; gap: 10px; padding: 15px 30px; border-radius: 50px; font-weight: 600; }\n",
        "        .consensus-badge.success { background: rgba(16,163,127,0.2); color: #10a37f; }\n",
        "        .consensus-badge.warning { background: rgba(255,193,7,0.2); color: #ffc107; }\n",
        "        .markdown-content h1,.markdown-content h2,.markdown-content h3 { margin: 1em 0 0.5em; }\n",
        "        .markdown-content p { margin-bottom: 1em; }\n",
        "        .markdown-content code { background: rgba(255,255,255,0.1); padding: 0.2em 0.4em; border-radius: 4px; }\n",
        "        .markdown-content pre { background: var(--bg-secondary); padding: 1em; border-radius: 8px; overflow-x: auto; }\n",
        "        .status-badge { padding: 6px 14px; border-radius: 20px; font-size: 0.85rem; font-weight: 600; }\n",
        "        .status-badge.no-revision { background: rgba(16,163,127,0.2); color: #10a37f; }\n",
        "        .status-badge.needs-revision { background: rgba(255,107,53,0.2); color: #ff6b35; }\n",
        "        .revision-badge { display: inline-block; background: rgba(255,193,7,0.2); color: #ffc107; padding: 4px 12px; border-radius: 20px; font-size: 0.75rem; margin-left: auto; }\n",
        "        @media (max-width: 900px) { .response-grid, .arbiter-grid { grid-template-columns: 1fr; } .input-wrapper { flex-direction: column; } }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <header class=\"header\">\n",
        "            <h1>ğŸ” AI PK System</h1>\n",
        "            <p>AI A â†” AI B cross-verification with OpenAI arbitration</p>\n",
        "        </header>\n",
        "        <div class=\"input-section\">\n",
        "            <div class=\"model-selectors\">\n",
        "                <div class=\"model-selector\"><label>Model A</label><select id=\"modelA\"><option value=\"gemini\">Gemini</option><option value=\"grok\">Grok</option><option value=\"doubao\">è±†åŒ…</option><option value=\"qwen\">åƒé—®</option></select></div>\n",
        "                <div class=\"model-selector\"><label>Model B</label><select id=\"modelB\"><option value=\"gemini\">Gemini</option><option value=\"grok\" selected>Grok</option><option value=\"doubao\">è±†åŒ…</option><option value=\"qwen\">åƒé—®</option></select></div>\n",
        "            </div>\n",
        "            <div class=\"input-wrapper\">\n",
        "                <input type=\"text\" class=\"question-input\" id=\"questionInput\" placeholder=\"Enter your question...\">\n",
        "                <button class=\"submit-btn\" id=\"submitBtn\" onclick=\"submitQuestion()\">Verify</button>\n",
        "            </div>\n",
        "        </div>\n",
        "        <div class=\"status-bar\" id=\"statusBar\"><div class=\"spinner\"></div><span id=\"statusText\">Processing...</span></div>\n",
        "        <div class=\"response-grid\">\n",
        "            <div class=\"response-card\"><div class=\"response-header\" id=\"headerA\" style=\"background:linear-gradient(135deg,#4285f4,#34a853)\"><div class=\"ai-icon\" id=\"iconA\">G</div><span class=\"response-title\" id=\"titleA\">Model A</span><span class=\"revision-badge\" id=\"badgeA\" style=\"display:none\"></span></div><div class=\"response-content\"><div id=\"responseA\"><span style=\"color:var(--text-secondary);font-style:italic\">Model A response...</span></div></div></div>\n",
        "            <div class=\"response-card\"><div class=\"response-header\" id=\"headerB\" style=\"background:linear-gradient(135deg,#ff6b35,#ff8c42)\"><div class=\"ai-icon\" id=\"iconB\">X</div><span class=\"response-title\" id=\"titleB\">Model B</span><span class=\"revision-badge\" id=\"badgeB\" style=\"display:none\"></span></div><div class=\"response-content\"><div id=\"responseB\"><span style=\"color:var(--text-secondary);font-style:italic\">Model B response...</span></div></div></div>\n",
        "        </div>\n",
        "        <div class=\"arbiter-section\">\n",
        "            <div class=\"arbiter-header\"><div class=\"ai-icon\">âš–ï¸</div><span class=\"response-title\">OpenAI Arbiter</span></div>\n",
        "            <div class=\"arbiter-content\">\n",
        "                <div class=\"arbiter-grid\">\n",
        "                    <div class=\"arbiter-item\"><div style=\"margin-bottom:10px;color:var(--text-secondary)\">Analysis of Model A</div><div id=\"arbiterA\"><span style=\"color:var(--text-secondary);font-style:italic\">Waiting...</span></div></div>\n",
        "                    <div class=\"arbiter-item\"><div style=\"margin-bottom:10px;color:var(--text-secondary)\">Analysis of Model B</div><div id=\"arbiterB\"><span style=\"color:var(--text-secondary);font-style:italic\">Waiting...</span></div></div>\n",
        "                </div>\n",
        "                <div class=\"consensus-banner\" id=\"consensusBanner\" style=\"display:none\"><div class=\"consensus-badge\" id=\"consensusBadge\"></div></div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    <script>\n",
        "        const modelColors = { gemini: {gradient:'linear-gradient(135deg,#4285f4,#34a853)',icon:'G'}, grok: {gradient:'linear-gradient(135deg,#ff6b35,#ff8c42)',icon:'X'}, doubao: {gradient:'linear-gradient(135deg,#00d4aa,#00a085)',icon:'è±†'}, qwen: {gradient:'linear-gradient(135deg,#ff5722,#e64a19)',icon:'åƒ'} };\n",
        "        let revisionsA=0, revisionsB=0;\n",
        "        function setStatus(msg,show=true) { document.getElementById('statusBar').classList.toggle('active',show); document.getElementById('statusText').textContent=msg; }\n",
        "        function renderMarkdown(t) { try{return marked.parse(t||'')} catch(e){return t} }\n",
        "        function formatArbiter(raw) {\n",
        "            try { let p=JSON.parse(raw); return `<span class=\"status-badge ${p.needs_revision?'needs-revision':'no-revision'}\">${p.needs_revision?'âš ï¸ Needs Revision':'âœ“ OK'}</span><p style=\"margin-top:10px\">${p.reason||''}</p>`; } catch(e) { return renderMarkdown(raw); }\n",
        "        }\n",
        "        async function submitQuestion() {\n",
        "            const q=document.getElementById('questionInput').value.trim();\n",
        "            if(!q) return alert('Enter a question');\n",
        "            document.getElementById('submitBtn').disabled=true; revisionsA=0; revisionsB=0;\n",
        "            document.getElementById('badgeA').style.display='none'; document.getElementById('badgeB').style.display='none';\n",
        "            setStatus('Initializing...');\n",
        "            try {\n",
        "                const res=await fetch('/verify',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({question:q,model_a:document.getElementById('modelA').value,model_b:document.getElementById('modelB').value})});\n",
        "                const reader=res.body.getReader(), decoder=new TextDecoder();\n",
        "                while(true) { const{done,value}=await reader.read(); if(done)break; decoder.decode(value).split('\\\\n').filter(l=>l.trim()).forEach(line=>{ try{handleUpdate(JSON.parse(line))}catch(e){} }); }\n",
        "            } catch(e) { setStatus('Error: '+e.message); }\n",
        "            document.getElementById('submitBtn').disabled=false; setStatus('',false);\n",
        "        }\n",
        "        function handleUpdate(d) {\n",
        "            if(d.type=='models') { ['A','B'].forEach((x,i)=>{ let m=i?d.model_b:d.model_a,c=modelColors[m]; document.getElementById('header'+x).style.background=c.gradient; document.getElementById('icon'+x).textContent=c.icon; document.getElementById('title'+x).textContent=m; }); }\n",
        "            else if(d.type=='status') setStatus(d.message);\n",
        "            else if(d.type=='model_a_initial') { let e=document.getElementById('responseA'); e.innerHTML=renderMarkdown(d.content); e.classList.add('markdown-content'); }\n",
        "            else if(d.type=='model_b_initial') { let e=document.getElementById('responseB'); e.innerHTML=renderMarkdown(d.content); e.classList.add('markdown-content'); }\n",
        "            else if(d.type=='model_a_revised') { revisionsA++; document.getElementById('responseA').innerHTML=renderMarkdown(d.content); document.getElementById('badgeA').textContent='Revised x'+revisionsA; document.getElementById('badgeA').style.display='inline-block'; }\n",
        "            else if(d.type=='model_b_revised') { revisionsB++; document.getElementById('responseB').innerHTML=renderMarkdown(d.content); document.getElementById('badgeB').textContent='Revised x'+revisionsB; document.getElementById('badgeB').style.display='inline-block'; }\n",
        "            else if(d.type=='arbiter') { document.getElementById('arbiterA').innerHTML=formatArbiter(d.model_a_analysis); document.getElementById('arbiterB').innerHTML=formatArbiter(d.model_b_analysis); }\n",
        "            else if(d.type=='consensus') { let b=document.getElementById('consensusBanner'),bg=document.getElementById('consensusBadge'); b.style.display='block'; bg.className='consensus-badge '+(d.reached?'success':'warning'); bg.innerHTML=(d.reached?'âœ“ Consensus Round '+d.round:'âš  Max Rounds Reached'); }\n",
        "        }\n",
        "        document.getElementById('questionInput').addEventListener('keypress',e=>{if(e.key=='Enter')submitQuestion();});\n",
        "    </script>\n",
        "</body>\n",
        "</html>'''\n",
        "\n",
        "print(f'âœ… HTML template loaded ({len(HTML_TEMPLATE)} bytes)')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Flask Routes\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return HTML_TEMPLATE\n",
        "\n",
        "@app.route('/models')\n",
        "def get_models():\n",
        "    return jsonify(AVAILABLE_MODELS)\n",
        "\n",
        "@app.route('/verify', methods=['POST'])\n",
        "def verify():\n",
        "    question = request.json.get('question', '')\n",
        "    model_a = request.json.get('model_a', 'gemini')\n",
        "    model_b = request.json.get('model_b', 'grok')\n",
        "    if not question.strip():\n",
        "        return jsonify({'error': 'Please enter a question'}), 400\n",
        "    if model_a not in AVAILABLE_MODELS: model_a = 'gemini'\n",
        "    if model_b not in AVAILABLE_MODELS: model_b = 'grok'\n",
        "\n",
        "    def generate():\n",
        "        yield json.dumps({'type':'models','model_a':model_a,'model_b':model_b,'model_a_info':AVAILABLE_MODELS[model_a],'model_b_info':AVAILABLE_MODELS[model_b]})+'\\n'\n",
        "        yield json.dumps({'type':'status','message':f'Getting {get_model_name(model_a)} response...'})+'\\n'\n",
        "        ok_a, answer_a = ask_model(model_a, question)\n",
        "        if not ok_a: yield json.dumps({'type':'error','source':'model_a','message':answer_a})+'\\n'; return\n",
        "        yield json.dumps({'type':'model_a_initial','content':answer_a})+'\\n'\n",
        "        yield json.dumps({'type':'status','message':f'Getting {get_model_name(model_b)} response...'})+'\\n'\n",
        "        ok_b, answer_b = ask_model(model_b, question)\n",
        "        if not ok_b: yield json.dumps({'type':'error','source':'model_b','message':answer_b})+'\\n'; return\n",
        "        yield json.dumps({'type':'model_b_initial','content':answer_b})+'\\n'\n",
        "        round_num, consensus = 1, False\n",
        "        while round_num <= MAX_REVISION_ROUNDS and not consensus:\n",
        "            yield json.dumps({'type':'status','message':f'Round {round_num}: Cross-verification...'})+'\\n'\n",
        "            ok_rb, review_b = ask_model(model_b, create_verification_prompt(question, answer_a))\n",
        "            if not ok_rb: yield json.dumps({'type':'error','message':review_b})+'\\n'; return\n",
        "            ok_ra, review_a = ask_model(model_a, create_verification_prompt(question, answer_b))\n",
        "            if not ok_ra: yield json.dumps({'type':'error','message':review_a})+'\\n'; return\n",
        "            yield json.dumps({'type':'status','message':f'Round {round_num}: OpenAI arbiter analyzing...'})+'\\n'\n",
        "            ok_arb_a, arbiter_a = ask_openai(create_arbiter_prompt(question, answer_a, review_b))\n",
        "            ok_arb_b, arbiter_b = ask_openai(create_arbiter_prompt(question, answer_b, review_a))\n",
        "            a_needs, a_corr = parse_arbiter_response(arbiter_a)\n",
        "            b_needs, b_corr = parse_arbiter_response(arbiter_b)\n",
        "            yield json.dumps({'type':'arbiter','round':round_num,'model_a_analysis':arbiter_a,'model_b_analysis':arbiter_b})+'\\n'\n",
        "            if not a_needs and not b_needs:\n",
        "                consensus = True\n",
        "                yield json.dumps({'type':'consensus','reached':True,'round':round_num})+'\\n'\n",
        "            else:\n",
        "                if a_needs:\n",
        "                    ok_rev_a, answer_a = ask_model(model_a, create_revision_prompt(question, answer_a, a_corr))\n",
        "                    yield json.dumps({'type':'model_a_revised','round':round_num,'content':answer_a})+'\\n'\n",
        "                if b_needs:\n",
        "                    ok_rev_b, answer_b = ask_model(model_b, create_revision_prompt(question, answer_b, b_corr))\n",
        "                    yield json.dumps({'type':'model_b_revised','round':round_num,'content':answer_b})+'\\n'\n",
        "                round_num += 1\n",
        "        if not consensus:\n",
        "            yield json.dumps({'type':'consensus','reached':False,'round':round_num-1})+'\\n'\n",
        "        yield json.dumps({'type':'final','model_a':answer_a,'model_b':answer_b,'consensus':consensus})+'\\n'\n",
        "    return Response(generate(), mimetype='application/x-ndjson')\n",
        "\n",
        "print('âœ… Flask routes defined')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Start the server with ngrok\n",
        "import threading\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f'\\nğŸš€ Public URL: {public_url}')\n",
        "print('\\nâš ï¸ Keep this notebook running! Click the URL above to access the AI PK System.')\n",
        "\n",
        "# Run Flask in a thread\n",
        "threading.Thread(target=lambda: app.run(port=5000, use_reloader=False)).start()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
